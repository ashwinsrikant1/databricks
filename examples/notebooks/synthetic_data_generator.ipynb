{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Synthetic Campaign Data Generator\n\nThis notebook demonstrates generating realistic synthetic advertising campaign data using the `dbldatagen` library. The generated data mimics real campaign schemas with proper distributions and realistic identifier patterns.\n\n## What this notebook does:\n1. **Setup**: Installs required dependencies and imports libraries\n2. **Reference**: Displays an image showing the target data schema\n3. **Generation**: Creates 10,000 rows of synthetic campaign data with 24 columns\n4. **Storage**: Writes data to Unity Catalog volumes as Parquet files\n5. **Verification**: Validates the written data\n6. **Alternative Storage**: Demonstrates saving as Delta tables\n\n## Use Cases:\n- Testing ETL pipelines with realistic data\n- Demo environments without exposing real customer data\n- Performance testing with large datasets\n- Development and staging environments"
  },
  {
   "cell_type": "markdown",
   "source": "## 1. Environment Setup\n\nFirst, we'll install the required `dbldatagen` library if it's not already available:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dbldatagen if not already installed\n",
    "%pip install dbldatagen"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "Now we'll import the necessary libraries for data generation and Spark operations:",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## 2. Schema Reference\n\nDisplay the reference image that shows the target data schema we want to replicate:",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## 3. Synthetic Data Generation\n\nNow we'll create a comprehensive data generator specification that produces realistic campaign data. This includes:\n\n- **Campaign identifiers**: Account IDs, campaign IDs, creative IDs (using realistic numeric patterns)\n- **Campaign metadata**: Types, reach estimates, run status, bid types\n- **Timestamps**: Creation and update times (Unix format)\n- **Configuration flags**: Donation settings, duplication scenarios\n- **Creative properties**: Media types, backend creative types, locations\n\nThe generator uses weighted distributions to mimic real-world data patterns:",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## 4. Data Quality Verification\n\nLet's examine the generated data to ensure it meets our expectations:",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## 5. Unity Catalog Volume Storage\n\nConfigure the Unity Catalog destination where we'll store the synthetic data. Update these paths according to your environment:",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "Write the synthetic data to Unity Catalog as Parquet files (efficient columnar format):",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## 6. Alternative Storage: Delta Tables\n\nDelta Lake provides additional benefits over Parquet including:\n- **ACID transactions**: Ensures data consistency\n- **Time Travel**: Query historical versions of data  \n- **Schema Evolution**: Handle schema changes gracefully\n- **Optimized Performance**: Better query performance with automatic optimization\n\nThis approach is recommended for production workloads:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dbldatagen as dg\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, LongType, TimestampType\n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "Create a managed Delta table in Unity Catalog:",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "Query the Delta table to verify it was created successfully:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image file (for reference)\n",
    "image_path = '/Users/ashwin.srikant/Downloads/554207516_1143861547080971_5209848696419928616_n (2).png'\n",
    "\n",
    "# Display the image\n",
    "from IPython.display import Image, display\n",
    "display(Image(filename=image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic campaign data based on the schema seen in the image\n",
    "num_rows = 10000\n",
    "seed = 42\n",
    "\n",
    "# Create synthetic data generator\n",
    "data_spec = (\n",
    "    dg.DataGenerator(spark, name=\"campaign_data\", rows=num_rows, seedMethod='hash_fieldname', random=True)\n",
    "    .withColumn(\"type\", \"string\", values=[\"33\", \"7\", \"12\"], weights=[5, 3, 2])\n",
    "    .withColumn(\"campaign_reach_estimate\", \"integer\", minValue=0, maxValue=1000000)\n",
    "    .withColumn(\"ad_duplication_scenario\", \"integer\", values=[0, 1], weights=[7, 3])\n",
    "    .withColumn(\"bid_type\", \"string\", values=[\"7\", \"3\", \"5\"], random=True)\n",
    "    .withColumn(\"time_updated\", \"long\", minValue=1750000000, maxValue=1760000000)\n",
    "    .withColumn(\"time_created\", \"long\", minValue=1750000000, maxValue=1760000000)\n",
    "    .withColumn(\"parent_campaign_id\", \"string\", template=r\"\\d{20}\", random=True)\n",
    "    .withColumn(\"account_id\", \"string\", template=r\"\\d{15}\", random=True)\n",
    "    .withColumn(\"oid\", \"string\", template=r\"\\d{20}\", random=True)\n",
    "    .withColumn(\"account_group_id\", \"string\", template=r\"\\d{20}\", random=True)\n",
    "    .withColumn(\"creative_media_type\", \"string\", values=[\"3\", \"1\", \"2\"], random=True)\n",
    "    .withColumn(\"creative_id\", \"string\", template=r\"\\d{15}\", random=True)\n",
    "    .withColumn(\"account_admarket_id\", \"string\", template=r\"\\d{20}\", random=True)\n",
    "    .withColumn(\"is_donation_enabled\", \"string\", values=[\"0\", \"1\"], weights=[8, 2])\n",
    "    .withColumn(\"www_request_id\", \"string\", template=r\"AJX7_VksS[A-Za-z0-9]{10}\", random=True)\n",
    "    .withColumn(\"run_status\", \"string\", values=[\"17\", \"8\", \"4\"], weights=[5, 3, 2])\n",
    "    .withColumn(\"audit_version\", \"string\", values=[\"4\", \"5\", \"3\"], random=True)\n",
    "    .withColumn(\"target_spec_id\", \"string\", template=r\"\\d{20}\", random=True)\n",
    "    .withColumn(\"backend_creative_type\", \"string\", values=[\"0\", \"1\", \"2\"], random=True)\n",
    "    .withColumn(\"location\", \"string\", values=[\"3\", \"1\", \"2\", \"4\"], random=True)\n",
    "    .withColumn(\"delivery_id\", \"string\", template=r\"\\d{20}\", random=True)\n",
    "    .withColumn(\"creator_id\", \"string\", template=r\"\\d{15}\", random=True)\n",
    "    .withColumn(\"parent_campaign_group_id\", \"string\", template=r\"\\d{20}\", random=True)\n",
    "    .withColumn(\"parent_adgroup_id\", \"string\", template=r\"\\d{20}\", random=True)\n",
    ")\n",
    "\n",
    "# Build the dataframe\n",
    "df_synthetic = data_spec.build()\n",
    "\n",
    "# Show sample data\n",
    "display(df_synthetic.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show data statistics\n",
    "print(f\"Total rows generated: {df_synthetic.count()}\")\n",
    "df_synthetic.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Unity Catalog volume path\n",
    "# Update these values according to your Unity Catalog setup\n",
    "catalog_name = \"main\"  # Update with your catalog name\n",
    "schema_name = \"default\"  # Update with your schema name\n",
    "volume_name = \"synthetic_data\"  # Update with your volume name\n",
    "\n",
    "# Full volume path\n",
    "volume_path = f\"/Volumes/{catalog_name}/{schema_name}/{volume_name}/campaign_data\"\n",
    "\n",
    "print(f\"Writing data to: {volume_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data to Unity Catalog volume as parquet\n",
    "df_synthetic.write \\\n",
    "    .format(\"parquet\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(volume_path)\n",
    "\n",
    "print(f\"Successfully wrote {num_rows} rows to {volume_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the data was written correctly\n",
    "df_read = spark.read.format(\"parquet\").load(volume_path)\n",
    "print(f\"Rows read from volume: {df_read.count()}\")\n",
    "display(df_read.limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Write as Delta Table\n",
    "\n",
    "You can also write the data as a Delta table in Unity Catalog for better performance and features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Write as a Delta table in Unity Catalog\n",
    "table_name = f\"{catalog_name}.{schema_name}.campaign_synthetic_data\"\n",
    "\n",
    "df_synthetic.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(table_name)\n",
    "\n",
    "print(f\"Successfully wrote data to table: {table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the table\n",
    "df_table = spark.table(table_name)\n",
    "display(df_table.limit(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}